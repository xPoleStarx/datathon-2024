{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost modeli için eğitim yapılıyor...\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "XGBoost için en iyi RMSE: 5.522961190798652\n",
      "En iyi hiperparametreler: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 1}\n",
      "\n",
      "CatBoost modeli için eğitim yapılıyor...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "CatBoost için en iyi RMSE: 5.5053772651954445\n",
      "En iyi hiperparametreler: {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n",
      "\n",
      "Model Karşılaştırma Sonuçları:\n",
      "      Model  Best_RMSE\n",
      "1  CatBoost   5.505377\n",
      "0   XGBoost   5.522961\n",
      "\n",
      "En iyi model: CatBoost\n",
      "\n",
      "Tahminler 'submission.csv' dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "# Gerekli kütüphaneleri import edelim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor  # CatBoost'u ekledik\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Veri Setini Yükleme\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test_x.csv')\n",
    "\n",
    "# 2. Veri Ön İşleme ve Temizleme\n",
    "\n",
    "# a. Yaş hesaplama ve 'Yas' sütununu ekleme\n",
    "def calculate_age(born):\n",
    "    try:\n",
    "        born = pd.to_datetime(born, errors='coerce', infer_datetime_format=True)\n",
    "        today = pd.to_datetime('today')\n",
    "        age = today.year - born.year - ((today.month, today.day) < (born.month, born.day))\n",
    "        return int(age)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Yaşları hesaplayalım\n",
    "train_df['Yas'] = train_df['Dogum Tarihi'].apply(calculate_age)\n",
    "test_df['Yas'] = test_df['Dogum Tarihi'].apply(calculate_age)\n",
    "\n",
    "# Üniversite okuma sayısını hesaplama\n",
    "def calculate_university_count(row):\n",
    "    if pd.isna(row['Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite']):\n",
    "        return 1  # Sadece şu anki üniversite var\n",
    "    else:\n",
    "        return 2  # Hem şu anki üniversite hem de önceki var\n",
    "\n",
    "# Yeni sütunu ekleyelim\n",
    "train_df['Universite Okuma Sayisi'] = train_df.apply(calculate_university_count, axis=1)\n",
    "test_df['Universite Okuma Sayisi'] = test_df.apply(calculate_university_count, axis=1)\n",
    "\n",
    "# b. Gereksiz sütunları çıkarma\n",
    "columns_to_drop = ['Dogum Tarihi', 'Dogum Yeri', 'Lise Adi', 'Lise Adi Diger', 'Lise Sehir',\n",
    "                   'Lise Bolum Diger', 'Lise Bolumu', 'Daha Önceden Mezun Olunduysa, Mezun Olunan Üniversite']\n",
    "train_df.drop(columns=columns_to_drop, inplace=True)\n",
    "test_df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# c. Binary sütunların kodlanması\n",
    "binary_columns = [\n",
    "    'Burs Aliyor mu?', 'Daha Once Baska Bir Universiteden Mezun Olmus',\n",
    "    'Baska Bir Kurumdan Burs Aliyor mu?', 'Girisimcilik Kulupleri Tarzi Bir Kulube Uye misiniz?',\n",
    "    'Profesyonel Bir Spor Daliyla Mesgul musunuz?', 'Aktif olarak bir STK üyesi misiniz?',\n",
    "    'Stk Projesine Katildiniz Mi?', 'Girisimcilikle Ilgili Deneyiminiz Var Mi?', 'Ingilizce Biliyor musunuz?'\n",
    "]\n",
    "\n",
    "for col in binary_columns:\n",
    "    train_df[col] = train_df[col].map({'Evet': 1, 'Hayır': 0})\n",
    "    test_df[col] = test_df[col].map({'Evet': 1, 'Hayır': 0})\n",
    "\n",
    "# 'Cinsiyet' sütunu için kodlama\n",
    "train_df['Cinsiyet'] = train_df['Cinsiyet'].map({'Erkek': 2, 'Kadın': 1, 'ERKEK': 2, 'KADIN': 1, 'Belirtmek istemiyorum': 0})\n",
    "test_df['Cinsiyet'] = test_df['Cinsiyet'].map({'Erkek': 2, 'Kadın': 1, 'ERKEK': 2, 'KADIN': 1, 'Belirtmek istemiyorum': 0})\n",
    "\n",
    "# 'Universite Turu' sütunu için kodlama\n",
    "train_df['Universite Turu'] = train_df['Universite Turu'].map({'Özel': 1, 'Devlet': 0})\n",
    "test_df['Universite Turu'] = test_df['Universite Turu'].map({'Özel': 1, 'Devlet': 0})\n",
    "\n",
    "# d. Kategorik değişkenlerin kodlanması\n",
    "categorical_columns = train_df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Ortak sütunlar için birleşik veri seti oluşturma (Label Encoding için)\n",
    "combined_df = pd.concat([train_df[categorical_columns], test_df[categorical_columns]], axis=0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    combined_df[col] = combined_df[col].astype(str)\n",
    "    combined_df[col] = le.fit_transform(combined_df[col])\n",
    "\n",
    "# Tekrar ayırma\n",
    "train_df[categorical_columns] = combined_df.iloc[:len(train_df)][categorical_columns]\n",
    "test_df[categorical_columns] = combined_df.iloc[len(train_df):][categorical_columns]\n",
    "\n",
    "# e. Eksik değerlerin doldurulması\n",
    "# Eğitim verisindeki eksik değerleri dolduralım\n",
    "for col in train_df.columns:\n",
    "    if train_df[col].isnull().sum() > 0:\n",
    "        if train_df[col].dtype in ['float64', 'int64']:\n",
    "            median = train_df[col].median()\n",
    "            train_df[col].fillna(median, inplace=True)\n",
    "        else:\n",
    "            mode = train_df[col].mode()[0]\n",
    "            train_df[col].fillna(mode, inplace=True)\n",
    "\n",
    "# Test verisindeki eksik değerleri eğitim verisiyle dolduralım\n",
    "for col in test_df.columns:\n",
    "    if test_df[col].isnull().sum() > 0:\n",
    "        if test_df[col].dtype in ['float64', 'int64']:\n",
    "            median = train_df[col].median()  # Eğitim setindeki medyanı kullan\n",
    "            test_df[col].fillna(median, inplace=True)\n",
    "        else:\n",
    "            mode = train_df[col].mode()[0]  # Eğitim setindeki en sık değeri kullan\n",
    "            test_df[col].fillna(mode, inplace=True)\n",
    "\n",
    "# 3. Özellik Mühendisliği\n",
    "\n",
    "# a. Yeni özellikler\n",
    "\n",
    "# Ebeveynlerin Eğitim Ortalaması\n",
    "train_df['Ebeveyn Egitim Ort'] = (train_df['Anne Egitim Durumu'] + train_df['Baba Egitim Durumu']) / 2\n",
    "test_df['Ebeveyn Egitim Ort'] = (test_df['Anne Egitim Durumu'] + test_df['Baba Egitim Durumu']) / 2\n",
    "\n",
    "# 1. Ebeveyn Çalışma Durumu\n",
    "def map_working_status(status):\n",
    "    if pd.isnull(status):\n",
    "        return 0\n",
    "    status = str(status).lower()\n",
    "    if status in ['evet', 'çalışıyor', 'evet çalışıyor']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['Anne Calisiyor'] = df['Anne Calisma Durumu'].apply(map_working_status)\n",
    "    df['Baba Calisiyor'] = df['Baba Calisma Durumu'].apply(map_working_status)\n",
    "    \n",
    "    # Create 'Ebeveyn Calisma Durumu'\n",
    "    def parents_working_status(row):\n",
    "        if row['Anne Calisiyor'] == 1 and row['Baba Calisiyor'] == 1:\n",
    "            return 2  # İkisi de çalışıyor\n",
    "        elif row['Anne Calisiyor'] == 1 or row['Baba Calisiyor'] == 1:\n",
    "            return 1  # Biri çalışıyor\n",
    "        else:\n",
    "            return 0  # Hiçbiri çalışmıyor\n",
    "    \n",
    "    df['Ebeveyn Calisma Durumu'] = df.apply(parents_working_status, axis=1)\n",
    "\n",
    "# 2. Aile Geliri\n",
    "education_mapping = {\n",
    "    'Eğitim Yok': 0,\n",
    "    'İlkokul Mezunu': 1,\n",
    "    'Ortaokul Mezunu': 2,\n",
    "    'Lise': 3,\n",
    "    'Üniversite': 4,\n",
    "    'Yüksek Lisans / Doktora': 5\n",
    "}\n",
    "\n",
    "sector_mapping = {\n",
    "    'Kamu': 2,\n",
    "    'Özel Sektör': 2,\n",
    "    'Emekli': 1,\n",
    "    'Ev Hanımı': 0,\n",
    "    '0': 0,\n",
    "    'Diğer': 1,\n",
    "    np.nan: 0\n",
    "}\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    # Map education levels\n",
    "    df['Anne Egitim Seviyesi'] = df['Anne Egitim Durumu'].map(education_mapping).fillna(0)\n",
    "    df['Baba Egitim Seviyesi'] = df['Baba Egitim Durumu'].map(education_mapping).fillna(0)\n",
    "    \n",
    "    # Map sectors\n",
    "    df['Anne Sektor Skoru'] = df['Anne Sektor'].map(sector_mapping).fillna(0)\n",
    "    df['Baba Sektor Skoru'] = df['Baba Sektor'].map(sector_mapping).fillna(0)\n",
    "    \n",
    "    # 'Anne Calisiyor' ve 'Baba Calisiyor' zaten oluşturuldu\n",
    "    \n",
    "    # Calculate income score for each parent\n",
    "    df['Anne Gelir Skoru'] = df['Anne Egitim Seviyesi'] * df['Anne Sektor Skoru'] * df['Anne Calisiyor']\n",
    "    df['Baba Gelir Skoru'] = df['Baba Egitim Seviyesi'] * df['Baba Sektor Skoru'] * df['Baba Calisiyor']\n",
    "    \n",
    "    # Total family income score\n",
    "    df['Aile Geliri'] = df['Anne Gelir Skoru'] + df['Baba Gelir Skoru']\n",
    "\n",
    "# 3. Şehir ve Üniversite Puanı\n",
    "\n",
    "# Üniversite Puanı\n",
    "university_scores = train_df.groupby('Universite Adi')['Degerlendirme Puani'].mean().to_dict()\n",
    "\n",
    "train_df['Universite Puani'] = train_df['Universite Adi'].map(university_scores)\n",
    "test_df['Universite Puani'] = test_df['Universite Adi'].map(university_scores)\n",
    "\n",
    "mean_univ_score = train_df['Universite Puani'].mean()\n",
    "test_df['Universite Puani'].fillna(mean_univ_score, inplace=True)\n",
    "\n",
    "# Şehir Puanı\n",
    "city_scores = train_df.groupby('Ikametgah Sehri')['Degerlendirme Puani'].mean().to_dict()\n",
    "\n",
    "train_df['Sehir Puani'] = train_df['Ikametgah Sehri'].map(city_scores)\n",
    "test_df['Sehir Puani'] = test_df['Ikametgah Sehri'].map(city_scores)\n",
    "\n",
    "mean_city_score = train_df['Sehir Puani'].mean()\n",
    "test_df['Sehir Puani'].fillna(mean_city_score, inplace=True)\n",
    "\n",
    "# 4. Lise Türü Puanı\n",
    "lise_turu_scores = train_df.groupby('Lise Turu')['Degerlendirme Puani'].mean().to_dict()\n",
    "\n",
    "train_df['Lise Turu Puani'] = train_df['Lise Turu'].map(lise_turu_scores)\n",
    "test_df['Lise Turu Puani'] = test_df['Lise Turu'].map(lise_turu_scores)\n",
    "\n",
    "mean_lise_turu_score = train_df['Lise Turu Puani'].mean()\n",
    "test_df['Lise Turu Puani'].fillna(mean_lise_turu_score, inplace=True)\n",
    "\n",
    "# 5. STK Deneyimi\n",
    "for df in [train_df, test_df]:\n",
    "    df['STK Deneyimi'] = df['Aktif olarak bir STK üyesi misiniz?'] + df['Stk Projesine Katildiniz Mi?']\n",
    "\n",
    "# 4. Modelleme\n",
    "\n",
    "# a. Hedef değişkeni ve özellikleri ayırma\n",
    "X = train_df.drop(['Degerlendirme Puani', 'id'], axis=1)\n",
    "y = train_df['Degerlendirme Puani']\n",
    "\n",
    "# b. Eğitim ve test setlerinin sütunlarını eşleştirme\n",
    "test_features = test_df.drop('id', axis=1)\n",
    "common_cols = X.columns.intersection(test_features.columns)\n",
    "X = X[common_cols]\n",
    "test_features = test_features[common_cols]\n",
    "\n",
    "# c. Cross-Validation ve Model Seçimi\n",
    "\n",
    "# Kullanılacak modeller ve hiperparametreler\n",
    "models = {\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 5, 7],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'subsample': [0.8, 1]\n",
    "        }\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'model': CatBoostRegressor(verbose=0, random_state=42),  # CatBoost modelini ekledik\n",
    "        'params': {\n",
    "            'iterations': [100, 200],\n",
    "            'depth': [4, 6, 8],\n",
    "            'learning_rate': [0.01, 0.1],\n",
    "            'l2_leaf_reg': [1, 3, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Performans sonuçlarını saklamak için\n",
    "model_scores = []\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for model_name, mp in models.items():\n",
    "    print(f\"{model_name} modeli için eğitim yapılıyor...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=mp['model'],\n",
    "        param_grid=mp['params'],\n",
    "        cv=kf,\n",
    "        scoring='neg_mean_squared_error',\n",
    "        n_jobs=1,  # Paralel işleme kapatıldı\n",
    "        verbose=1\n",
    "    )\n",
    "    grid_search.fit(X, y)\n",
    "    best_rmse = np.sqrt(-grid_search.best_score_)\n",
    "    print(f\"{model_name} için en iyi RMSE: {best_rmse}\")\n",
    "    print(f\"En iyi hiperparametreler: {grid_search.best_params_}\\n\")\n",
    "    model_scores.append({\n",
    "        'Model': model_name,\n",
    "        'Best_RMSE': best_rmse,\n",
    "        'Best_Params': grid_search.best_params_,\n",
    "        'Best_Estimator': grid_search.best_estimator_\n",
    "    })\n",
    "\n",
    "# Sonuçları DataFrame olarak saklayalım\n",
    "results_df = pd.DataFrame(model_scores).sort_values(by='Best_RMSE')\n",
    "print(\"Model Karşılaştırma Sonuçları:\")\n",
    "print(results_df[['Model', 'Best_RMSE']])\n",
    "\n",
    "# En iyi modeli seçelim\n",
    "best_model_info = results_df.iloc[0]\n",
    "best_model = best_model_info['Best_Estimator']\n",
    "print(f\"\\nEn iyi model: {best_model_info['Model']}\")\n",
    "\n",
    "# 5. En İyi Model ile Tahmin ve Sonuç Dosyasının Oluşturulması\n",
    "\n",
    "# Tüm veri üzerinde (X, y) en iyi modeli eğitelim\n",
    "best_model.fit(X, y)\n",
    "\n",
    "# Test verisi üzerinde tahmin yapalım\n",
    "test_predictions = best_model.predict(test_features)\n",
    "\n",
    "# Negatif tahminleri 0'a eşitleyelim (Eğer gerekiyorsa)\n",
    "test_predictions = np.where(test_predictions < 0, 0, test_predictions)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Degerlendirme Puani': test_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nTahminler 'submission.csv' dosyasına kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
